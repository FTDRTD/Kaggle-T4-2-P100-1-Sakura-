{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://github.com/fatedier/frp/releases/download/v0.60.0/frp_0.60.0_linux_amd64.tar.gz\n!tar -xzf frp_0.60.0_linux_amd64.tar.gz\n\nfrpc_config = \"\"\"\n[common]\nserver_addr = frp-fly.top\nserver_port = 7000\ntoken= ym7f9ywune99j1hdj09uizzt6kokw6wg\n\nsakura_mode = true\nlogin_fail_exit = false\n\n[AIi]\n# id = 17538306\ntype = tcp\nlocal_ip = 127.0.0.1\nlocal_port = 5000\nremote_port = 29881\n\"\"\"\n\nwith open('frp_0.60.0_linux_amd64/frpc.ini', 'w') as f:\n    f.write(frpc_config)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T13:39:42.055392Z","iopub.execute_input":"2024-09-09T13:39:42.055739Z","iopub.status.idle":"2024-09-09T13:39:44.984612Z","shell.execute_reply.started":"2024-09-09T13:39:42.055700Z","shell.execute_reply":"2024-09-09T13:39:44.983353Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2024-09-09 13:39:42--  https://github.com/fatedier/frp/releases/download/v0.60.0/frp_0.60.0_linux_amd64.tar.gz\nResolving github.com (github.com)... 140.82.116.3\nConnecting to github.com (github.com)|140.82.116.3|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://objects.githubusercontent.com/github-production-release-asset-2e65be/48378947/879af83b-767b-4fd3-b702-c68c6c8cf307?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240909%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240909T133943Z&X-Amz-Expires=300&X-Amz-Signature=6ac9f1ff4e52ebfba54750be377af1e7ce920a3c401a69d4fdb22484789f23a3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=48378947&response-content-disposition=attachment%3B%20filename%3Dfrp_0.60.0_linux_amd64.tar.gz&response-content-type=application%2Foctet-stream [following]\n--2024-09-09 13:39:43--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/48378947/879af83b-767b-4fd3-b702-c68c6c8cf307?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240909%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240909T133943Z&X-Amz-Expires=300&X-Amz-Signature=6ac9f1ff4e52ebfba54750be377af1e7ce920a3c401a69d4fdb22484789f23a3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=48378947&response-content-disposition=attachment%3B%20filename%3Dfrp_0.60.0_linux_amd64.tar.gz&response-content-type=application%2Foctet-stream\nResolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\nConnecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 12373547 (12M) [application/octet-stream]\nSaving to: 'frp_0.60.0_linux_amd64.tar.gz'\n\nfrp_0.60.0_linux_am 100%[===================>]  11.80M  --.-KB/s    in 0.08s   \n\n2024-09-09 13:39:43 (149 MB/s) - 'frp_0.60.0_linux_amd64.tar.gz' saved [12373547/12373547]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/SakuraLLM/Sakura-13B-Galgame.git\n%cd Sakura-13B-Galgame\n!pip install -q -U torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n!pip install -q auto-gptq\n!pip install -q -r requirements.txt\n!pip install -q pyngrok\n\n# install localtunnel\n!npm install -g localtunnel","metadata":{"execution":{"iopub.status.busy":"2024-09-09T13:39:50.819458Z","iopub.execute_input":"2024-09-09T13:39:50.819882Z","iopub.status.idle":"2024-09-09T13:44:42.982687Z","shell.execute_reply.started":"2024-09-09T13:39:50.819839Z","shell.execute_reply":"2024-09-09T13:44:42.981674Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'Sakura-13B-Galgame'...\nremote: Enumerating objects: 981, done.\u001b[K\nremote: Counting objects: 100% (439/439), done.\u001b[K\nremote: Compressing objects: 100% (226/226), done.\u001b[K\nremote: Total 981 (delta 298), reused 286 (delta 210), pack-reused 542 (from 1)\u001b[K\nReceiving objects: 100% (981/981), 297.65 KiB | 9.92 MiB/s, done.\nResolving deltas: 100% (538/538), done.\n/kaggle/working/Sakura-13B-Galgame\n\u001b[K\u001b[?25hm##################\u001b[0m] | reify:yargs: \u001b[32;40mhttp\u001b[0m \u001b[35mfetch\u001b[0m GET 200 https://registry.npmjs.o\u001b[0m\u001b[Kpmjs.o\u001b[0m\u001b[K\nadded 22 packages in 2s\n\n3 packages are looking for funding\n  run `npm fund` for details\n\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m \n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m New \u001b[33mminor\u001b[39m version of npm available! \u001b[31m10.5.0\u001b[39m -> \u001b[32m10.8.3\u001b[39m\n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m Changelog: \u001b[36mhttps://github.com/npm/cli/releases/tag/v10.8.3\u001b[39m\n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m Run \u001b[32mnpm install -g npm@10.8.3\u001b[39m to update!\n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m \n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"MODEL = \"SakuraLLM/Sakura-13B-LNovel-v0_8-8bit\"\n\n# 使用 localtunnel 进行内网穿透\nimport subprocess\nimport threading\nimport urllib\n\ndef start_localtunnel():\n    subprocess.Popen(['lt', '--port', '8000'])\n    print(\"localtunnel started successfully.\")\n\nthreading.Thread(target=start_localtunnel, daemon=True).start()\n\nprint(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://loca.lt/mytunnelpassword').read().decode('utf8').strip(\"\\n\"))\n\n\n# 启动 server.py\nwhile True:\n    try:\n        subprocess.run([\n            \"python\", \"server.py\",\n            \"--model_name_or_path\", MODEL,\n            \"--use_gptq_model\",\n            \"--model_version\", \"0.8\",\n            \"--trust_remote_code\",\n            \"--no-auth\"\n        ])\n    except Exception as e:\n        print(f\"Error running server.py: {e}\")\n        break","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}